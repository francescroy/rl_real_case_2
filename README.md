# Toy problem modeled as a Markov decision process (MDP)

The idea in this project is to model a toy problem as a MDP 
and find the best policy under two scenarios: if we now the dynamics (model-based MDP) or if 
we don't (model-free MDP)